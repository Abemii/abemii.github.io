<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=format-detection content="telephone=no">
<title>[Reading] Training data-efficient image transformers & distillation through attention | 我的...</title>
<link rel=apple-touch-icon sizes=180x180 href=https://abemii.github.io/apple-touch-icon.png>
<link rel=icon type=image/png sizes=32x32 href=https://abemii.github.io/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=https://abemii.github.io/favicon-16x16.png>
<link rel=manifest href=https://abemii.github.io/manifest.json>
<link rel=mask-icon href=https://abemii.github.io/safari-pinned-tab.svg color=#ff3db4>
<meta name=theme-color content="#ffffff">
<link rel=stylesheet href=https://abemii.github.io/css/main.min.e34415025514319010e741089e6920454053855755ba465f66943ad102d2cb08.css>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-220178174-1','auto'),ga('set','anonymizeIp',!0),ga('send','pageview'))</script></head>
<body>
<nav>
<header>
<div class=site-title>
<a href=https://abemii.github.io/>我的...</a>
</div>
</header>
<div class=nav-menu>
<a class="color-link nav-link" href=https://abemii.github.io/about/>About</a>
<a class="color-link nav-link" href=https://abemii.github.io/tags/>Tags</a>
<a class="color-link nav-link" href=https://abemii.github.io/archives/>Archives</a>
<a class="color-link nav-link" href=https://abemii.github.io/index.xml target=_blank rel=noopener type=application/rss+xml>RSS</a>
</div>
<footer class=footer>
<div class=social-icons>
<a class=social-icon href=https://twitter.com/abemii_ target=_blank rel=noopener title=Twitter><svg width="28" height="28" viewBox="0 0 28 28" fill="#ababab" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink"><path d="M8.991284 24.971612c10.189152.0 15.761088-8.441388 15.761088-15.761088C24.752372 8.970656 24.747512 8.731868 24.736496 8.494376 25.818008 7.712564 26.758256 6.737 27.5 5.62622c-.992628.440856-2.060748.738072-3.181248.871992 1.14372-.685584 2.02176-1.770768 2.435832-3.064176-1.070496.6345-2.25558 1.095984-3.517344 1.344492-1.010772-1.076652-2.450412-1.75014-4.043412-1.75014-3.059424.0-5.540292 2.480868-5.540292 5.539104.0.434808.0487079999999995.857412.14364 1.26306C9.19346 9.599108 5.11106 7.39472 2.3792 4.04294c-.476172.818424-.750168 1.769688-.750168 2.784132.0 1.921968.97794 3.61854 2.464992 4.61106C3.185528 11.41016 2.331788 11.160464 1.585184 10.745096 1.583888 10.768208 1.583888 10.791428 1.583888 10.815728c0 2.683152 1.909764 4.922856 4.4442 5.43078C5.562932 16.373084 5.07326 16.44134 4.56782 16.44134 4.210988 16.44134 3.863876 16.406024 3.526484 16.34144c.70524 2.200824 2.750112 3.802356 5.174928 3.8475-1.896264 1.485756-4.284576 2.37114-6.879924 2.37114C1.374476 22.56008.93362 22.534592.5 22.4834c2.451708 1.571076 5.362524 2.488212 8.491284 2.488212"/></svg>
</a>
<a class=social-icon href=https://github.com/Abemii/ target=_blank rel=noopener title=GitHub><svg width="28" height="28" viewBox="0 0 28 28" fill="#ababab" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink"><path d="M13.9988029 1.32087331C6.82105037 1.32087331 1 7.14112562 1 14.3212723c0 5.7436386 3.72454649 10.6157955 8.89038951 12.3348169C10.5408085 26.7757983 10.7778323 26.374374 10.7778323 26.0296121 10.7778323 25.7215609 10.7666595 24.9035493 10.760275 23.8189856 7.14426471 24.6042767 6.38131925 22.0760223 6.38131925 22.0760223c-.59136253-1.5019491-1.44369072-1.9017772-1.44369072-1.9017772C3.75729765 19.3682044 5.02701126 19.3841656 5.02701126 19.3841656 6.33183953 19.4759425 7.01817121 20.7241085 7.01817121 20.7241085c1.15958133 1.9863716 3.04300319 1.4125664 3.78360289 1.0797753.1181129-.8395592.4540962-1.4125663.8251942-1.7373768C8.74038491 19.7385043 5.70536235 18.6228163 5.70536235 13.6413251c0-1.4189508.50676816-2.5801283 1.33834679-3.4883207C6.90963504 9.82420367 6.46351945 8.50181809 7.17139875 6.71256734c0 0 1.09094816-.34955032 3.57451115 1.33276037C11.78259 7.75642995 12.8950858 7.61277914 14.000399 7.60719272 15.1049142 7.61277914 16.2166119 7.75642995 17.2548881 8.04532771c2.4819669-1.68231069 3.571319-1.33276037 3.571319-1.33276037C21.5356825 8.50181809 21.0895669 9.82420367 20.9562909 10.1530044 21.7894656 11.0611968 22.2922435 12.2223743 22.2922435 13.6413251c0 4.9942601-3.039811 6.0931889-5.935173 6.4148071.4660671.401424200000001.8818564 1.194696.8818564 2.4077473C17.2389269 24.2012564 17.2229657 25.603448 17.2229657 26.0296121 17.2229657 26.3775663 17.4575954 26.7821827 18.116793 26.6552912 23.2786458 24.9322794 27 20.0633148 27 14.3212723 27 7.14112562 21.1789496 1.32087331 13.9988029 1.32087331"/></svg>
</a>
</div>
<p><a href=https://github.com/kimcc/hugo-theme-noteworthy target=_blank rel=noopener>Noteworthy theme</a></p>
<p><a href=https://gohugo.io target=_blank rel=noopener>Built with Hugo</a></p>
<script src=https://abemii.github.io/js/main.min.c1aee25a817e9beb1f9c4afd9d62311227a7f5e46720e404dc1dda97281f47f2.js integrity="sha256-wa7iWoF+m+sfnEr9nWIxEien9eRnIOQE3B3alygfR/I=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css integrity=sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.js integrity=sha384-2BKqo+exmr9su6dir+qCw08N2ZKRucY4PrGQPPWU1A7FtlCGjmEGFqXCv5nyM5Ij crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script>
</footer>
</nav>
<div id=content class=content-container>
<h1 class=post-title>[Reading] Training data-efficient image transformers & distillation through attention</h1>
<time>February 25, 2022</time>
<div>
<p>
<p>DeiT 論文を読んだのでそのメモ。</p>
<p>多くの ViT 研究において、 DeiT の学習スキームがフォローされている。
最近読んだ ShiftViT<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> において言及されており、ちゃんと読んでおこうと思っていた。</p>
<h2 id=書誌情報>書誌情報</h2>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bib data-lang=bib><span style=color:#a6e22e>@misc</span>{touvron2021training,
      <span style=color:#a6e22e>title</span>=<span style=color:#e6db74>{Training data-efficient image transformers &amp; distillation through attention}</span>, 
      <span style=color:#a6e22e>author</span>=<span style=color:#e6db74>{Hugo Touvron and Matthieu Cord and Matthijs Douze and Francisco Massa and Alexandre Sablayrolles and Hervé Jégou}</span>,
      <span style=color:#a6e22e>year</span>=<span style=color:#e6db74>{2021}</span>,
      <span style=color:#a6e22e>eprint</span>=<span style=color:#e6db74>{2012.12877}</span>,
      <span style=color:#a6e22e>archivePrefix</span>=<span style=color:#e6db74>{arXiv}</span>,
      <span style=color:#a6e22e>primaryClass</span>=<span style=color:#e6db74>{cs.CV}</span>
}
</code></pre></div><ul>
<li>図表は特に言及のない限り本論文からの引用。</li>
</ul>
<h2 id=概要>概要</h2>
<ul>
<li>ViT と同じネットワーク構造のモデルを用い、学習方法を工夫することで精度を上げ、
また、学習に必要な計算リソース・時間を大きく短縮した。</li>
<li>蒸留トークン (distillation token) を用いた蒸留手法を提案。 class token とは別の token を用いて
教師モデルからの教師信号を学習させることで、より性能を高められる。</li>
<li>学習時の工夫について詳細な分析を行い、よくまとめている。</li>
</ul>
<h2 id=distillation>Distillation</h2>
<ul>
<li>
<p>Distillation (蒸留) の方法は、 Soft と Hard に大別される。</p>
<ul>
<li>
<p>Soft なほうは、生徒モデルの logits $ Z_s $ と 教師モデルの logits $ Z_t $ を KL-loss を使って最小化する。</p>
</li>
<li>
<p>Hard なほうでは、 教師モデルの hard decision $ y_t = \argmax_c Z_t(c) $ を使い、 Cross entropy で最適化する。</p>
<ul>
<li>この方法は Soft と異なりパラメータフリーであるという良さがある。</li>
<li>さらに実験では label smoothing と呼ばれる手法を取り入れている。
すなわち、 真なクラスを $ 1 - \epsilon $ とし、その他のクラスを $\epsilon$ で等分するといった方法である。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>蒸留トークン (distillation token)</p>
<ul>
<li>クラストークンとは別に、 蒸留トークンを加える。</li>
<li>蒸留トークンもクラストークンと同様に使うが、 クラストークンと異なり、
こちらは教師モデルの hard decision を教師信号とする。</li>
<li>クラストークンと蒸留トークンは同じような出力をするが、全く同じではない。</li>
</ul>
</li>
</ul>
<img class=article-image src=https://abemii.github.io/posts/reading-deit/figures/fig2.png alt>
<p>実験結果より、</p>
<ul>
<li>蒸留トークンを使わない場合、3 種類の蒸留手法 (行わない/ソフト/ハード) のうち ハードが最も良かった。</li>
<li>蒸留トークンを使用し、 ハード蒸留を使って学習を行った後、
クラス予測には、クラス embedding, 蒸留 embedding, 両方の3種類の方法を使うことが考えられる。
このうち最も結果がよかったのは、 蒸留 embedding を使うもので、
これは、教師モデルである convnet の帰納バイアスの恩恵を受けているからだろうと著者は考えている。</li>
</ul>
<h2 id=学習戦略に関する-ablation-study>学習戦略に関する ablation study</h2>
<h3 id=重みの初期化>重みの初期化</h3>
<p>Transformer は比較的初期化方法に敏感であり、方法によっては収束しない場合がある。
最終的に切断正規分布 (truncated normal distribution) を使用して重みの初期化を行った。</p>
<h3 id=data-augmentation>data augmentation</h3>
<ul>
<li>Transformer では convolution に比べより多くのデータ量が必要。
<ul>
<li>convolution はより多くの事前分布を統合することができる。</li>
<li>同じ大きさのデータセットで学習を行うためには、大規模な data augmentation を
行う必要がある。</li>
</ul>
</li>
<li>データ効率の良い学習を行うために、異なるタイプの強力な data augmentation を評価。
<ul>
<li>Auto-augment, rand-augment, random erasing により性能が向上。</li>
<li>ほとんどの data augm. 手法は有用であることが分かった。</li>
</ul>
</li>
</ul>
<h3 id=正則化と最適化>正則化と最適化</h3>
<ul>
<li>最適化アルゴリズム
<ul>
<li>ViT と同じく AdamW を用い、学習率を同じ値を用いることが最も良い結果となった。</li>
<li>ただし、 Weight Decay の値は、収束のためにより小さい値を用いることとした。</li>
</ul>
</li>
<li>Stochastic depth
<ul>
<li>Dropout は ノードをオフにする = 横方向にネットワークを小さくする。</li>
<li>Stochastic depth は Layer 数を変化させる = 縦方向にネットワークを小さくする。</li>
<li>Short なネットワークを学習し、 Deep なネットワークを得ることができる。</li>
<li>特に深い transformer の収束を促進させる。</li>
</ul>
</li>
<li>正則化
<ul>
<li>Mixup
</li>
<li>Cutmix
</li>
</ul>
</li>
<li>repeated augmentation
<ul>
<li>一つの画像からいくつかの augmentation 画像をつくることで、
1 バッチ内で同じサンプルを複数回読み込ませる手法。</li>
<li>提案した学習スキームの鍵となる構成要素。</li>
</ul>
</li>
</ul>
<h3 id=exponential-moving-average-ema>Exponential Moving Average (EMA)</h3>
<ul>
<li>EMA を行うことで、0.1 pt 程度性能が向上したが、 fine tuning すると、同じ結果となった。</li>
</ul>
<h3 id=異なる解像度での-fine-tuning>異なる解像度での fine tuning</h3>
<ul>
<li>学習は解像度は 224 で行ったが、 fine-tuning は 384 で行った。</li>
<li>Fixing the train-test resolution discrepancy
<ul>
<li>学習時の解像度は、テスト時より小さい解像度のほうが良いという先行研究。</li>
<li>FixefficientNet と異なり、学習時の augmentation は弱めずに行う。</li>
</ul>
</li>
<li>Positional embeddings の補間
<ul>
<li>bilinear ではなく、 bicubic を用いて補間を行った。</li>
<li>bilinear を用いると、その補間された verctor の $ l_2 $ ノルムが
隣接する vector のノルムよりも小さくなってしまう。</li>
<li>これを fine-tuning せずに Transformer に適用すると、性能が著しく落ちる。</li>
<li>bicubic を用いると、vector の norm が維持される。</li>
</ul>
</li>
</ul>
<h3 id=学習時間>学習時間</h3>
<ul>
<li>batch norm を使っていないので、 batch size を減らしても性能に影響しない。
よって、大きなモデルを学習するのが簡単になる。</li>
</ul>
<h2 id=参照>参照</h2>
<ul>
<li><a href=https://zenn.dev/takoroy/scraps/ced7059a36d846>https://zenn.dev/takoroy/scraps/ced7059a36d846</a>
<ul>
<li>takoroy さんによる本論文のメモ。</li>
</ul>
</li>
<li><a href=https://qiita.com/supersaiakujin/items/eb0553a1ef1d46bd03fa>https://qiita.com/supersaiakujin/items/eb0553a1ef1d46bd03fa</a>
<ul>
<li>stochastic depth について、 supersaiakujin さんによる記事。</li>
</ul>
</li>
</ul>
<section class=footnotes role=doc-endnotes>
<hr>
<ol>
<li id=fn:1 role=doc-endnote>
<p><a href=https://arxiv.org/pdf/2201.10801.pdf>https://arxiv.org/pdf/2201.10801.pdf</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p>
</li>
</ol>
</section>
</p>
</div>
<div class=page-footer>
<hr class=footer-divider>
<a class=tag href=https://abemii.github.io/tags/vit>#ViT</a>
<a class=tag href=https://abemii.github.io/tags/transformer>#Transformer</a>
<a class=tag href=https://abemii.github.io/tags/deep-learning>#Deep Learning</a>
<a class=tag href=https://abemii.github.io/tags/computer-vision>#Computer Vision</a>
</div>
<link rel=stylesheet type=text/css href=https://abemii.github.io/css/katex.min.css crossorigin=anonymous>
<script type=text/javascript src=https://abemii.github.io/js/katex.min.js crossorigin=anonymous></script>
<script type=text/javascript src=https://abemii.github.io/js/auto-render.min.js onload=renderMathInElement(document.body) crossorigin=anonymous></script>
</div>
<footer class=footer-mobile>
<div class=social-icons>
<a class=social-icon href=https://twitter.com/abemii_ target=_blank rel=noopener title=Twitter><svg width="28" height="28" viewBox="0 0 28 28" fill="#ababab" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink"><path d="M8.991284 24.971612c10.189152.0 15.761088-8.441388 15.761088-15.761088C24.752372 8.970656 24.747512 8.731868 24.736496 8.494376 25.818008 7.712564 26.758256 6.737 27.5 5.62622c-.992628.440856-2.060748.738072-3.181248.871992 1.14372-.685584 2.02176-1.770768 2.435832-3.064176-1.070496.6345-2.25558 1.095984-3.517344 1.344492-1.010772-1.076652-2.450412-1.75014-4.043412-1.75014-3.059424.0-5.540292 2.480868-5.540292 5.539104.0.434808.0487079999999995.857412.14364 1.26306C9.19346 9.599108 5.11106 7.39472 2.3792 4.04294c-.476172.818424-.750168 1.769688-.750168 2.784132.0 1.921968.97794 3.61854 2.464992 4.61106C3.185528 11.41016 2.331788 11.160464 1.585184 10.745096 1.583888 10.768208 1.583888 10.791428 1.583888 10.815728c0 2.683152 1.909764 4.922856 4.4442 5.43078C5.562932 16.373084 5.07326 16.44134 4.56782 16.44134 4.210988 16.44134 3.863876 16.406024 3.526484 16.34144c.70524 2.200824 2.750112 3.802356 5.174928 3.8475-1.896264 1.485756-4.284576 2.37114-6.879924 2.37114C1.374476 22.56008.93362 22.534592.5 22.4834c2.451708 1.571076 5.362524 2.488212 8.491284 2.488212"/></svg>
</a>
<a class=social-icon href=https://github.com/Abemii/ target=_blank rel=noopener title=GitHub><svg width="28" height="28" viewBox="0 0 28 28" fill="#ababab" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink"><path d="M13.9988029 1.32087331C6.82105037 1.32087331 1 7.14112562 1 14.3212723c0 5.7436386 3.72454649 10.6157955 8.89038951 12.3348169C10.5408085 26.7757983 10.7778323 26.374374 10.7778323 26.0296121 10.7778323 25.7215609 10.7666595 24.9035493 10.760275 23.8189856 7.14426471 24.6042767 6.38131925 22.0760223 6.38131925 22.0760223c-.59136253-1.5019491-1.44369072-1.9017772-1.44369072-1.9017772C3.75729765 19.3682044 5.02701126 19.3841656 5.02701126 19.3841656 6.33183953 19.4759425 7.01817121 20.7241085 7.01817121 20.7241085c1.15958133 1.9863716 3.04300319 1.4125664 3.78360289 1.0797753.1181129-.8395592.4540962-1.4125663.8251942-1.7373768C8.74038491 19.7385043 5.70536235 18.6228163 5.70536235 13.6413251c0-1.4189508.50676816-2.5801283 1.33834679-3.4883207C6.90963504 9.82420367 6.46351945 8.50181809 7.17139875 6.71256734c0 0 1.09094816-.34955032 3.57451115 1.33276037C11.78259 7.75642995 12.8950858 7.61277914 14.000399 7.60719272 15.1049142 7.61277914 16.2166119 7.75642995 17.2548881 8.04532771c2.4819669-1.68231069 3.571319-1.33276037 3.571319-1.33276037C21.5356825 8.50181809 21.0895669 9.82420367 20.9562909 10.1530044 21.7894656 11.0611968 22.2922435 12.2223743 22.2922435 13.6413251c0 4.9942601-3.039811 6.0931889-5.935173 6.4148071.4660671.401424200000001.8818564 1.194696.8818564 2.4077473C17.2389269 24.2012564 17.2229657 25.603448 17.2229657 26.0296121 17.2229657 26.3775663 17.4575954 26.7821827 18.116793 26.6552912 23.2786458 24.9322794 27 20.0633148 27 14.3212723 27 7.14112562 21.1789496 1.32087331 13.9988029 1.32087331"/></svg>
</a>
</div>
<div class=footer-mobile-links>
<p><a href=https://github.com/kimcc/hugo-theme-noteworthy target=_blank rel=noopener>Noteworthy theme</a></p>
<span class=divider-bar>|</span>
<p><a href=https://gohugo.io target=_blank rel=noopener>Built with Hugo</a></p>
</div>
<script src=https://abemii.github.io/js/main.min.c1aee25a817e9beb1f9c4afd9d62311227a7f5e46720e404dc1dda97281f47f2.js integrity="sha256-wa7iWoF+m+sfnEr9nWIxEien9eRnIOQE3B3alygfR/I=" crossorigin=anonymous></script>
</footer>
</body>
</html>